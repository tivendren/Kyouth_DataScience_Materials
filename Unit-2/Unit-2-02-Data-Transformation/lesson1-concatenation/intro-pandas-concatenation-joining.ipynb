{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "## Merging and Concatenation with pandas\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives\n",
    "- Practice concatenating dataframes using pandas\n",
    "- Join pandas dataframes using SQL-style join operations\n",
    "- Remove duplicate rows or columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Overview of concatenation and joining](#introduction)\n",
    "- [Concatenation using pandas](#pandas_concatenation)\n",
    "- [Identifying and removing duplicates](#removing_duplicates)\n",
    "- [SQL-style joins using pandas](#pandas_joins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "\n",
    "### Overview of concatenation and joining\n",
    "\n",
    "---\n",
    "\n",
    "**Concatenation** is the process of joining separate objects along a dimension to create a new single object. In\n",
    "computer programming and data processing, two or more character strings are sometimes concatenated for the purpose of saving space or so that they can be addressed as a **single item**.\n",
    "\n",
    "In pandas, we will be concatenating dataframes together **along rows or columns**. \n",
    "\n",
    "**Joins** with pandas happen when columns of two DataFrames are **joined together on index or on a key column**. The concept is the same as **SQL joins**. In pandas, joins are done typically with the `.merge()` function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas_concatenation'></a>\n",
    "\n",
    "### Concatenation using pandas\n",
    "\n",
    "---\n",
    "\n",
    "It is often the case that you  would like to concatenate two dataframes together. Perhaps your data is split up into two groups of subjects with the same variables/columns and you want to join them together (stacking vertically - adding rows). Or perhaps you have new variables for all of your existing subjects (stacking horizontally - adding columns).\n",
    "\n",
    "Below we have two simple datasets we can use to practice pandas concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                    index=[4, 5, 6, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas we can use the `pd.concat` function to stack DataFrames vertically or horizontally. `pd.concat()` takes a list of pandas dataframes as its first argument, and then an axis keyword argument indicating how to concatenate the dataframes. \n",
    "\n",
    "Setting `axis=0` will concatenate the DataFrames vertically (adding rows)\n",
    "\n",
    "**Concatenate `df1` and `df2` by stacking them vertically.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical concatenation\n",
    "pd.concat([df1, df2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Concatenate `df1` and `df2` by stacking them horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal concatenation\n",
    "pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that because the pandas **index** are different for the two dataframes, it fills in null values. Perhaps we don't care about the row labels during the horizontal concatenation. If you reset the index for `df2` prior to the concatenation it will not fill in null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Horizontal concatenation ignoring row labels\n",
    "pd.concat([df1, df2.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='removing_duplicates'></a>\n",
    "\n",
    "### Identifying and Removing Duplicates\n",
    "\n",
    "Sometimes when we combine data we may come across data that is duplicated. For a data set that has millions of rows, it will be difficult to identify these duplicated rows manually. We should always check for duplicate data, especially when one of the columns must be unique.\n",
    "\n",
    "Let's see how we can do this using a sample DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3', 'A1', 'A4'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3', 'B1', 'B4'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3', 'C1', 'C2'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3', 'D1', 'D3']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there duplicates? It's hard to tell...\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for duplicates\n",
    "\n",
    "The `duplicated` function returns a Series with boolean values showing whether a row is a duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `subset=` parameter to check for duplicates on specific columns, for example a column that should be a unique value.\n",
    "\n",
    "Use the `keep=` parameter to determine which row should be considered a duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values: subset=None, keep='first'\n",
    "df3.duplicated(subset=['C'], keep='last')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use the boolean mask to show the specific duplicated rows\n",
    "df3[df3.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing duplicate rows\n",
    "\n",
    "Once you have determined the duplicate rows should be removed, you can use `drop_duplicates`. To change the original DataFrame you would have to set `inplace=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicates\n",
    "df3.drop_duplicates(subset=['C'], keep='first', inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set inplace=True and check that the duplicates are really removed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pandas_joins'></a>\n",
    "\n",
    "### Left, right, inner, and outer joins in pandas\n",
    "\n",
    "---\n",
    "\n",
    "The pandas `merge` function allows us to join together DataFrames using columns as keys.\n",
    "\n",
    "Below we have two dataframes with information on `subject_id`, `first_name`, and `last_name`. We also have a third dataframe with information on `subject_id` and `test_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5'],\n",
    "        'first_name': ['Alex', 'Amy', 'Allen', 'Alice', 'Ayoung'],\n",
    "        'last_name': ['Anderson', 'Ackerman', 'Ali', 'Aoni', 'Atiches']}\n",
    "df_a = pd.DataFrame(raw_data)\n",
    "df_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['4', '5', '6', '7', '8'],\n",
    "        'first_name': ['Billy', 'Brian', 'Bran', 'Bryce', 'Betty'],\n",
    "        'last_name': ['Bonder', 'Black', 'Balwner', 'Brice', 'Btisan']}\n",
    "df_b = pd.DataFrame(raw_data)\n",
    "df_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {\n",
    "        'subject_id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "        'test_id': [51, 15, 15, 61, 16, 14, 15, 1, 61, 16]}\n",
    "df_n = pd.DataFrame(raw_data)\n",
    "df_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pandas `pd.merge()` for SQL-style joins**\n",
    "\n",
    "A left join produces a complete set of records from `df_a`, with the matching records (where available) in `df_b`. If there is no match, the right side will contain null.\n",
    "\n",
    "The pandas `pd.merge()` command has arguments:\n",
    "- left-hand dataset\n",
    "- right-hand dataset\n",
    "- `on=` : keyword argument specifying the key column to join the dataframes on\n",
    "- `how=` : keyword argument specifying the type of join (left, right, inner, outer)\n",
    "\n",
    "#### Left join `df_b` onto `df_a` by `subject_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Right join `df_b` onto `df_a` by `subject_id`\n",
    "\n",
    "Merge with a right join produces a complete set of records from `df_b`, with the matching records (where available) in `df_a`. If there is no match, the left side will contain null.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right join\n",
    "pd.merge(df_a, df_b, on='subject_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer join `df_b` onto `df_a` by `subject_id`\n",
    "\n",
    "An outer join produces the set of all records in `df_a` and `df_b`, with matching records from both sides where available. If there is no match, the missing side will contain null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outer join\n",
    "# pd.merge(df_a, df_b, on='subject_id', how=...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inner join `df_b` onto `df_a` by `subject_id`\n",
    "\n",
    "An inner join produces only the set of records that match in both df_a and df_b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join\n",
    "# pd.merge(df_a, df_b, on='subject_id', how=...?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the information in `df_a`, `df_b` and `df_n` using joins\n",
    "\n",
    "No information should be lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine the information in the three datasets only where information is contained in all rows of the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
